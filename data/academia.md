### Academia
An exhausting list of all my academic projects can be found on [my Google Scholar page](https://scholar.google.pl/citations?user=YiwwR6EAAAAJ). Below I present selected ones.

<br/>
#### <img src="https://raw.githubusercontent.com/ModelOriented/auditor/master/man/figures/logo.png" width="50"> Audit of machine learning models
A tool for model-agnostic validation, collected techniques facilitate assessing and comparing the goodness of fit and performance of models. In addition, they may be used for the analysis of the similarity of residuals and the identification of outliers and influential observations. The examination is carried out by diagnostic scores and visual verification.<br/>
The work is published in a paper [auditor: an R Package for Model-Agnostic Visual Validation and Diagnostics](https://doi.org/10.32614/RJ-2019-036) in the R Journal.<br/>
The R package [auditor](https://github.com/ModelOriented/auditor) is available on CRAN.


<br/>
#### <img src="https://raw.githubusercontent.com/MI2DataLab/WildNLP/master/logo.png" width="70"> Coruption robustness of neural NLP systems 
A framework for testing model stability in a natural setting where text corruptions such as keyboard errors or misspelling occur.<br/>
Framework is published in the paper: [Models in the Wild: On Corruption Robustness of Neural NLP Systems](https://doi.org/10.1007/978-3-030-36718-3_20) on the International Conference on Neural Information Processing.<br/>
The framework is availible as Python library [wild-nlp](https://github.com/MI2DataLab/WildNLP)

<br/>
#### <img src="https://raw.githubusercontent.com/ModelOriented/rSAFE/master/man/figures/logo.png" width="50"> Interpretable feature engineering
A framework that uses elastic black boxes as supervisor models to create simpler, less opaque, yet still accurate and interpretable glass box models.<br/>
A framework is published as a paper [Simpler is better: Lifting interpretability-performance trade-off via automated feature engineering](https://doi.org/10.1016/j.dss.2021.113556).in Decision Support Systems.<br/>
The [R package rSAFE](https://github.com/ModelOriented/rSAFE) is available on CRAN.

<br/>
#### <img src="https://raw.githubusercontent.com/ModelOriented/EloML/master/man/figures/logo.png" width="50"> Elo rating system for machine learning models (in progress)
An Elo-based rating system for machine learning models and Elo-based Predictive Power (EPP) score reinvent the idea of benchmarking models.<br/>
A paper currently is in a review process in Nature Machine Intelligence, the preliminary version is available as [arXiv preprint](https://arxiv.org/abs/2006.02293).<br/>
The method is implemented in the [EloML R package](https://github.com/ModelOriented/EloML).
